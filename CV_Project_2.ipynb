{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "id": "6hBOkP4D1jCo"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import albumentations as A\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import (Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, Input, Concatenate, LayerNormalization)\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import MeanSquaredError\n",
        "from tensorflow.keras.metrics import MeanAbsoluteError\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "0wNEijd_1jCp"
      },
      "outputs": [],
      "source": [
        "# Load and preprocess the data\n",
        "def load_data(image_folder, metadata_path, num_samples=None):\n",
        "    # Load metadata\n",
        "    metadata = pd.read_csv(metadata_path)\n",
        "\n",
        "    # If num_samples is provided, take the first 'num_samples' rows\n",
        "    if num_samples:\n",
        "        metadata = metadata.head(num_samples)\n",
        "\n",
        "    images = []\n",
        "    missing_images = []\n",
        "\n",
        "    for index, row in metadata.iterrows():\n",
        "        image_file = os.path.join(image_folder, str(row['id'])+'.jpg')  # Adjust 'id' column if necessary\n",
        "        image = cv2.imread(image_file)\n",
        "\n",
        "        # Check if the image was loaded successfully\n",
        "        if image is not None:\n",
        "            images.append(image)\n",
        "        else:\n",
        "            missing_images.append(image_file)\n",
        "            print(f\"Warning: Image {image_file} could not be loaded.\")\n",
        "\n",
        "    # Normalize pixel values to [0, 1]\n",
        "    images = np.array(images) / 255.0\n",
        "\n",
        "    return images, metadata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZazForb1jCq",
        "outputId": "687064ba-a8e7-4ded-f47c-c89b8f3dcc49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 7680 entries, 0 to 7679\n",
            "Data columns (total 7 columns):\n",
            " #   Column            Non-Null Count  Dtype\n",
            "---  ------            --------------  -----\n",
            " 0   id                7680 non-null   int64\n",
            " 1   shapeset          7680 non-null   int64\n",
            " 2   type              7680 non-null   int64\n",
            " 3   total_height      7680 non-null   int64\n",
            " 4   instability_type  7680 non-null   int64\n",
            " 5   cam_angle         7680 non-null   int64\n",
            " 6   stable_height     7680 non-null   int64\n",
            "dtypes: int64(7)\n",
            "memory usage: 420.1 KB\n"
          ]
        }
      ],
      "source": [
        "# Load the data\n",
        "image_folder = '/content/train'\n",
        "metadata_path = 'train.csv'\n",
        "images, metadata = load_data(image_folder, metadata_path)\n",
        "\n",
        "metadata.info()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_augmentation = A.Compose([\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.Rotate(limit=20, p=0.5),\n",
        "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_test_augmentation = A.Compose([\n",
        "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])"
      ],
      "metadata": {
        "id": "Bj4uf8tPnikC"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "3n2XmBbr1jCx"
      },
      "outputs": [],
      "source": [
        "train_metadata, val_metadata, train_labels, val_labels = train_test_split(metadata, metadata['stable_height'], test_size=0.2, random_state=42)\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "def load_and_preprocess_image(filepath):\n",
        "    image = load_img(filepath)\n",
        "    return image\n",
        "\n",
        "train_images = np.array([load_and_preprocess_image(os.path.join(image_folder, str(fname)+'.jpg')) for fname in train_metadata['id']])\n",
        "for img in train_images:\n",
        "  augmented = train_augmentation(image=img)\n",
        "  img = augmented['image']\n",
        "\n",
        "# Load images for validation\n",
        "val_images = np.array([load_and_preprocess_image(os.path.join(image_folder, str(fname)+'.jpg')) for fname in val_metadata['id']])\n",
        "for img in val_images:\n",
        "  augmented = val_test_augmentation(image=img)\n",
        "  img = augmented['image']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "id": "Ia1x-fyp1jCx"
      },
      "outputs": [],
      "source": [
        "# Define CNN model for image input\n",
        "image_input = Input(shape=(train_images.shape[1], train_images.shape[2], 3))\n",
        "x = LayerNormalization(axis=[-1,-2,-3])(image_input)\n",
        "x = Conv2D(32, (3, 3), activation='relu')(image_input)\n",
        "x = MaxPooling2D(pool_size=(3, 3))(x)\n",
        "x = Conv2D(64, (3, 3), activation='relu')(x)\n",
        "x = MaxPooling2D(pool_size=(3, 3))(x)\n",
        "x = Conv2D(128, (3, 3), activation='relu')(x)\n",
        "x = MaxPooling2D(pool_size=(3, 3))(x)\n",
        "x = Flatten()(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = layers.Dense(512, activation='relu')(x)\n",
        "x = layers.Dense(1, activation='linear')(x)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model(inputs=image_input, outputs=x)\n",
        "model.compile(optimizer='adam', loss=MeanSquaredError(), metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "gy64TFAln5hy"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TeCObqLK1jCz",
        "outputId": "703e7252-9931-4ef6-f239-71f036489f29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "96/96 [==============================] - 39s 393ms/step - loss: 10996.1221 - accuracy: 0.2059 - val_loss: 2.5119 - val_accuracy: 0.2415\n",
            "Epoch 2/20\n",
            "96/96 [==============================] - 37s 387ms/step - loss: 2.5872 - accuracy: 0.2516 - val_loss: 2.2491 - val_accuracy: 0.2415\n",
            "Epoch 3/20\n",
            "96/96 [==============================] - 37s 386ms/step - loss: 2.2715 - accuracy: 0.2521 - val_loss: 2.1740 - val_accuracy: 0.2415\n",
            "Epoch 4/20\n",
            "96/96 [==============================] - 37s 386ms/step - loss: 2.1652 - accuracy: 0.2521 - val_loss: 2.2049 - val_accuracy: 0.2415\n",
            "Epoch 5/20\n",
            "96/96 [==============================] - 37s 389ms/step - loss: 2.0684 - accuracy: 0.2521 - val_loss: 2.2076 - val_accuracy: 0.2415\n",
            "Epoch 6/20\n",
            "96/96 [==============================] - 38s 395ms/step - loss: 2.0520 - accuracy: 0.2521 - val_loss: 2.1194 - val_accuracy: 0.2415\n",
            "Epoch 7/20\n",
            "96/96 [==============================] - 38s 392ms/step - loss: 2.0423 - accuracy: 0.2521 - val_loss: 2.2005 - val_accuracy: 0.2415\n",
            "Epoch 8/20\n",
            "96/96 [==============================] - 38s 393ms/step - loss: 1.9885 - accuracy: 0.2520 - val_loss: 2.0738 - val_accuracy: 0.2415\n",
            "Epoch 9/20\n",
            "96/96 [==============================] - 38s 393ms/step - loss: 2.0174 - accuracy: 0.2521 - val_loss: 2.1030 - val_accuracy: 0.2415\n",
            "Epoch 10/20\n",
            "96/96 [==============================] - 38s 394ms/step - loss: 2.0003 - accuracy: 0.2521 - val_loss: 2.1199 - val_accuracy: 0.2415\n",
            "Epoch 11/20\n",
            "96/96 [==============================] - 38s 392ms/step - loss: 1.9662 - accuracy: 0.2521 - val_loss: 2.0770 - val_accuracy: 0.2415\n",
            "Epoch 12/20\n",
            "96/96 [==============================] - 38s 395ms/step - loss: 1.9684 - accuracy: 0.2521 - val_loss: 2.1468 - val_accuracy: 0.2415\n",
            "Epoch 13/20\n",
            "96/96 [==============================] - 38s 393ms/step - loss: 1.9507 - accuracy: 0.2521 - val_loss: 2.1635 - val_accuracy: 0.2415\n",
            "Epoch 14/20\n",
            "96/96 [==============================] - 38s 392ms/step - loss: 1.9123 - accuracy: 0.2521 - val_loss: 2.6729 - val_accuracy: 0.2409\n",
            "Epoch 15/20\n",
            "96/96 [==============================] - 38s 393ms/step - loss: 1.9226 - accuracy: 0.2521 - val_loss: 2.0549 - val_accuracy: 0.2415\n",
            "Epoch 16/20\n",
            "96/96 [==============================] - 38s 391ms/step - loss: 1.9380 - accuracy: 0.2521 - val_loss: 2.0284 - val_accuracy: 0.2415\n",
            "Epoch 17/20\n",
            "96/96 [==============================] - 38s 394ms/step - loss: 1.8859 - accuracy: 0.2521 - val_loss: 2.0232 - val_accuracy: 0.2415\n",
            "Epoch 18/20\n",
            "96/96 [==============================] - 38s 395ms/step - loss: 1.8902 - accuracy: 0.2520 - val_loss: 2.0425 - val_accuracy: 0.2415\n",
            "Epoch 19/20\n",
            "96/96 [==============================] - 38s 391ms/step - loss: 1.9056 - accuracy: 0.2521 - val_loss: 2.1713 - val_accuracy: 0.2415\n",
            "Epoch 20/20\n",
            "96/96 [==============================] - 38s 391ms/step - loss: 1.8791 - accuracy: 0.2520 - val_loss: 2.0419 - val_accuracy: 0.2415\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_images,\n",
        "    train_labels,\n",
        "    validation_data=(val_images, val_labels),\n",
        "    epochs=20,\n",
        "    batch_size=batch_size\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fahjpFh41jC0"
      },
      "outputs": [],
      "source": [
        "# Plot training & validation accuracy and loss (optional)\n",
        "def plot_history(history):\n",
        "    plt.figure(figsize=(12, 4))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['mean_absolute_error'], label='Train MAE')\n",
        "    plt.plot(history.history['val_mean_absolute_error'], label='Validation MAE')\n",
        "    plt.title('Model Mean Absolute Error')\n",
        "    plt.ylabel('MAE')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['loss'], label='Train Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "    plt.title('Model Loss')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "plot_history(history)\n",
        "\n",
        "# Save the model\n",
        "model.save('cnn_with_metadata_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JcqDcY5-1jC0"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array # type: ignore\n",
        "\n",
        "# Define function to load and preprocess a single image\n",
        "def load_and_preprocess_single_image(filepath):\n",
        "    image = load_img(filepath, target_size=(64, 64))  # Ensure the size matches the training images\n",
        "    image = img_to_array(image) / 255.0  # Normalize pixel values\n",
        "    return image\n",
        "\n",
        "# Path to the image you want to test\n",
        "test_image_path = './COMP90086_2024_Project_test/test/33287.jpg'\n",
        "\n",
        "# Load and preprocess the test image\n",
        "test_image = load_and_preprocess_single_image(test_image_path)\n",
        "\n",
        "# Prepare the corresponding metadata for the test image\n",
        "# Ensure the metadata matches the feature columns used in training\n",
        "test_metadata = np.array([[2,1,6,2,1]])  # Replace with actual feature values\n",
        "\n",
        "# Expand dimensions to match the input shape (1, height, width, channels)\n",
        "test_image = np.expand_dims(test_image, axis=0)\n",
        "\n",
        "# Make a prediction\n",
        "predicted_value = model.predict([test_image, test_metadata])\n",
        "\n",
        "# Print the prediction result\n",
        "print(f'Predicted Value: {predicted_value[0][0]}')  # Assuming a single numerical output\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V28"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}